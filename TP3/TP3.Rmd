---
title: "R Notebook"
output: html_notebook
---
# TP3

## Pré-traitement

### recupération des données

importation des modules
```{r}
library(Matrix)
library(NLP)
library(tm)
library(irlba)
library(stats)
library(pROC)
library(parallel)
```

On construit des objects SimpleCorpus du package Text Mining

Sur ces coprus, on supprime les nombres, la ponctuation, et on tranfsorme toutes les majuscules en minuscules
```{r}
get_data <- function(src) {
  corpus <- SimpleCorpus(DirSource(src))
  corpus <- tm_map(corpus, removeNumbers)
  corpus <- tm_map(corpus, removePunctuation)
  corpus <- tm_map(corpus, content_transformer(tolower))
  return(corpus)
}

corpus_poly <- get_data('data/Poly')
corpus_udm <- get_data('data/UdM')
corpus_hec <- get_data('data/HEC')
corpus_uqam <- get_data('data/UQAM')

head(data.frame(text = sapply(corpus_poly, as.character)))
```
On va ensuite construire un grand corpus regroupant les corpus des 4 écoles

```{r}
corpus_tot <- get_data(c('data/Poly', 'data/UdM', 'data/HEC', 'data/UQAM'))
```

### matrices Termes-Documents

On utilise le package TM pour construire des matrices termes-documents

On supprime avant cela les "stop words", mots très fréquents et que l'on retrouve dans tout les corpus de textes francais. Ces mots ne comportent pas de semantique particulière (comme les prépositions, etc...)
On supprime aussi les deux groupe nominaux "titrecours" et "descriptioncours" qui seront en quantité égale dans tout les documents et qui par conséquents ne sont pas utiles dans ce travail
```{r}
to_matrix <- function(corpus) {
  corpus <- tm_map(corpus,removeWords, stopwords('french'))
  corpus <- tm_map(corpus, removeWords, c('titrecours', 'descriptioncours'))
  return(TermDocumentMatrix(corpus))
}

td_poly <- to_matrix(corpus_poly)
td_udm <- to_matrix(corpus_udm)
td_hec <- to_matrix(corpus_hec)
td_uqam <- to_matrix(corpus_uqam)

td_tot <- to_matrix(corpus_tot)

```

Une fois la matrice terme-document définie, on va définir la matrice Tf-Idf

```{r}
get_Tf_IDF <- function(td) {
  tf <- as.matrix(td)
  tf_copy <- tf
  tf_copy[tf_copy != 0] <- 1
  n_i <- rowSums(tf_copy)
  idf <- log(nDocs(td_tot)/n_i)
  tf_idf = tf * idf
  return(tf_idf)
}

# tf_idf <- get_Tf_IDF(td_tot)
tf_idf <- Matrix(get_Tf_IDF(td_tot), "dgCMatrix")
head(tf_idf[, 0:5])
```

On reduis le nombre de dimention de la matrice. On transposera la matrice auparavant pour obtenir une matrice document-terme
```{r}
dim_redu = 50

m.svd <- irlba(t(tf_idf), 50)
reduce_tf_idf <- m.svd$u[, 1:dim_redu] %*% diag(m.svd$d[1:dim_redu])
rownames(reduce_tf_idf) <- colnames(tf_idf)
head(reduce_tf_idf[, 1:5])
```

## Question 1 

**Quels sont les 10 cours les plus similaires à LOG2420 dans l'espace réduit à 50 dimensions? **

On va dans un premier temps récupérer les fonctions de similarité de la correction du TP1
```{r}
## Cosinus entre un vecteur v et chaque colonne dela matrice m
cosinus.vm <- function(v,m) { n <- sqrt(colSums(m^2)); (v %*% m)/(n * sqrt(sum(v^2))) }
## Cosinus des colonnes d'une matrice
cosinus.mm <- function(m) { n <- sqrt(colSums(m^2)); crossprod(m)/(n %o% n) }
# Trouve les indexes des premières 'n' valeurs maximales d'une matrice
max.nindex <- function(m, n=5) {
  i <- order(m, decreasing=TRUE)
  return(i[1:n])
}
min.nindex <- function(m, n=5) {
  i <- order(m)
  return(i[1:n])
}
```

On va ensuite selectionner l'indice du cours LOG2420

```{r}
i <- grep('LOG2420', as.character(rownames(reduce_tf_idf)))
```

On va enfin calculer la similarité des documents entre-eux, avec la méthode des cosinus (on transpose la matrice pour obtenir une matrice terme-document)

```{r}
reduce_tf_idf.cos <- cosinus.mm(t(reduce_tf_idf))
```

on selectionne les 10 cours les plus proches de LOG2420

```{r}
i.sim.cos <- max.nindex(reduce_tf_idf.cos[,i], 11)
data.frame(Cos=reduce_tf_idf.cos[i.sim.cos, i], Index=i.sim.cos)
```

## Question 2

**Effectuez une classification de cours par une approche supervisée**

Dans un premier temps on va selectionner les index des cours qui nous intéressent

```{r}
reduce_tf_idf.class <- subset(reduce_tf_idf, grepl("PSY|PHY", rownames(reduce_tf_idf)))

reduce_tf_idf.PSY <- subset(reduce_tf_idf, grepl("PSY", rownames(reduce_tf_idf)))

reduce_tf_idf.PHY <- subset(reduce_tf_idf, grepl("PHY", rownames(reduce_tf_idf)))
```

On va maintenant calculer l'erreur des deux classes respectives:

- On sépare les données en entrainement et en test (le code est tiré de la correction du TP 1)

```{r}
nfolds = 3
split_data <- function (nfolds, fold, m) {
  split <- rep(1:nfolds, length.out=nrow(m))[sample(nrow(m))]
  m.test.i <- (split==fold)
  m.train.i <- !m.test.i
  
  m.train <- m[m.train.i,]
  m.test <- m[m.test.i,]
  return(list("train" = m.train, "train.i" = m.train.i, "test" = m.test, "test.i" = m.test.i))
}
splited_tf_idf.PSY <- split_data(nfolds, nfolds, reduce_tf_idf.PSY)
splited_tf_idf.PHY <- split_data(nfolds, nfolds, reduce_tf_idf.PHY)
```

On va ensuite calculer le centroides de la classes

```{r}
centroide.PSY <- colMeans(splited_tf_idf.PSY$train)
centroide.PHY <- colMeans(splited_tf_idf.PHY$train)
```

On va maintenant calculer l'erreur générée par cet itération

Pour chaque vecteur correspondant à une description de cours, on va calculer sa similarité cosinus avec les deux centroide. On prédira la classe en sélectionnant le centroide le plus proche

```{r}
prediction.PSY <- data.frame(cours = rownames(splited_tf_idf.PSY$test),
                                     sim.PSY = as.double(cosinus.vm(centroide.PSY, t(splited_tf_idf.PSY$test))),
                                     sim.PHY = as.double(cosinus.vm(centroide.PHY, t(splited_tf_idf.PSY$test))))

prediction.PSY$pred.PSY <- apply(prediction.PSY, 1, function (v) {as.numeric(v['sim.PSY']) / (as.numeric(v['sim.PHY']) + as.numeric(v['sim.PSY']))})
prediction.PSY$pred.PHY <- apply(prediction.PSY, 1, function (v) {as.numeric(v['sim.PHY']) / (as.numeric(v['sim.PHY']) + as.numeric(v['sim.PSY']))})
prediction.PSY$is.PSY <- 1
prediction.PSY$is.PHY <- 0


prediction.PHY <- data.frame(cours = rownames(splited_tf_idf.PHY$test),
                                     sim.PSY = as.double(cosinus.vm(centroide.PSY, t(splited_tf_idf.PHY$test))),
                                     sim.PHY = as.double(cosinus.vm(centroide.PHY, t(splited_tf_idf.PHY$test))))

prediction.PHY$pred.PHY <- apply(prediction.PHY, 1, function (v) {as.numeric(v['sim.PHY']) / (as.numeric(v['sim.PHY']) + as.numeric(v['sim.PSY']))})
prediction.PHY$pred.PSY <- apply(prediction.PHY, 1, function (v) {as.numeric(v['sim.PSY']) / (as.numeric(v['sim.PHY']) + as.numeric(v['sim.PSY']))})
prediction.PHY$is.PHY <- 1
prediction.PHY$is.PSY <- 0

head(prediction.PHY)
```

Maintenant on peut construire des vecteurs pour fournir à la fonction ROC
```{r}
prediction.class <- rbind(prediction.PHY, prediction.PSY)
responce.PSY <- roc(prediction.class$is.PSY, prediction.class$pred.PSY, plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
            print.auc=TRUE, show.thres=TRUE, levels=c(0,1), direction="<")
responce.PHY <- roc(prediction.class$is.PHY, prediction.class$pred.PHY, plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
            print.auc=TRUE, show.thres=TRUE, levels=c(0,1), direction="<")
```
On peut remarquer que les deux courbes sont symétrique par rapport à x=-y. C'est normal car les deux probabilitées sont liées: P(psy) = 1 - P(phy)

Nous allons maintenant répeter toutes ces étapes n fois, en fonction du nombre de fold sélectionné
```{r}
get_auc <- function (m.PSY, m.PHY, nfolds) {
  result <- sapply(1:nfolds , function(fold) {
  
    # construction des ensemble d'apprentissage et de test
    
    split <- rep(1:nfolds, length.out=nrow(m.PSY))[sample(nrow(m.PSY))]
    m.PSY.test.i <- (split==fold)
    m.PSY.train.i <- !m.PSY.test.i
    
    m.PSY.test <- m.PSY[m.PSY.test.i,]
    m.PSY.train <- m.PSY[m.PSY.train.i,]
    
    split <- rep(1:nfolds, length.out=nrow(m.PHY))[sample(nrow(m.PHY))]
    m.PHY.test.i <- (split==fold)
    m.PHY.train.i <- !m.PHY.test.i
    
    m.PHY.test <- m.PHY[m.PHY.test.i,]
    m.PHY.train <- m.PHY[m.PHY.train.i,]
    
    # on determine les centroides
    centroide.PSY <- colMeans(m.PSY[m.PSY.train.i,])
    centroide.PHY <- colMeans(m.PHY[m.PHY.train.i,])
    
    # on construit un nouveau data frame pour PSY
    prediction.PSY <- data.frame(cours = rownames(m.PSY.test),
                                         sim.PSY = as.double(cosinus.vm(centroide.PSY, t(m.PSY.test))),
                                         sim.PHY = as.double(cosinus.vm(centroide.PHY, t(m.PSY.test))))
    
    prediction.PSY$pred.PSY <- apply(prediction.PSY, 1, function (v) {as.numeric(v['sim.PSY']) / (as.numeric(v['sim.PHY']) + as.numeric(v['sim.PSY']))})
    prediction.PSY$pred.PHY <- apply(prediction.PSY, 1, function (v) {as.numeric(v['sim.PHY']) / (as.numeric(v['sim.PHY']) + as.numeric(v['sim.PSY']))})
    prediction.PSY$is.PSY <- 1
    prediction.PSY$is.PHY <- 0
    
    # on construit un nouveau data frame pour PHY
    prediction.PHY <- data.frame(cours = rownames(m.PHY.test),
                                         sim.PSY = as.double(cosinus.vm(centroide.PSY, t(m.PHY.test))),
                                         sim.PHY = as.double(cosinus.vm(centroide.PHY, t(m.PHY.test))))
    
    prediction.PHY$pred.PHY <- apply(prediction.PHY, 1, function (v) {as.numeric(v['sim.PHY']) / (as.numeric(v['sim.PHY']) + as.numeric(v['sim.PSY']))})
    prediction.PHY$pred.PSY <- apply(prediction.PHY, 1, function (v) {as.numeric(v['sim.PSY']) / (as.numeric(v['sim.PHY']) + as.numeric(v['sim.PSY']))})
    prediction.PHY$is.PHY <- 1
    prediction.PHY$is.PSY <- 0
    
    # on recupère la valeur de AUC
    prediction.class <- rbind(prediction.PHY, prediction.PSY)
    responce.PSY <- roc(prediction.class$is.PSY, prediction.class$pred.PSY, levels=c(0,1), direction="<")
  })
  return(result)
}

results <- as.data.frame(t(get_auc(reduce_tf_idf.PSY, reduce_tf_idf.PHY, 3)))
mean(as.double(results$auc))
```
A partir de la fonction supérieure, nous allons essayer plusieures dimentions de SVD.

```{r}

get_auc_by_dimention <- function(dim_redu, tf_idf) {
  
  m.svd <- irlba(t(tf_idf), dim_redu)
  reduce_tf_idf <- m.svd$u[, 1:dim_redu] %*% diag(m.svd$d[1:dim_redu])
  rownames(reduce_tf_idf) <- colnames(tf_idf)

  reduce_tf_idf.PSY <- subset(reduce_tf_idf, grepl("PSY", rownames(reduce_tf_idf)))
  reduce_tf_idf.PHY <- subset(reduce_tf_idf, grepl("PHY", rownames(reduce_tf_idf)))
  
  results <- as.data.frame(t(get_auc(reduce_tf_idf.PSY, reduce_tf_idf.PHY, 3)))
  return(mean(as.double(results$auc)))
}
dim_min = 2
dim_max = 50
auc_by_dimentions <- mclapply(dim_min:dim_max, get_auc_by_dimention, tf_idf, mc.cores = detectCores())
plot(dim_min:dim_max, auc_by_dimentions)
```
## Question 3

**Effectuez une agglomération par k-means (k=2) et vérifiez si les classes PHY et PSY sont bien séparées par cette méthode**

On s'assure qu'il n'y a pas de valeur manquantes
```{r}
reduce_tf_idf.class[is.na(reduce_tf_idf.PSY)]
```

On peut donc procéder au K-mean sans se soucier de normaliser
On va d'abord créer un ensemble de test et d'entrainement
```{r}
# apply_k_mean <- function(reduce_tf_idf.class) {
nfolds = 3
splited_tf_idf.class <- split_data(nfolds, nfolds, reduce_tf_idf.class)
```

On exécute l'algorithme k-mean sur l'ensemble de test
```{r}
k_mean_res <- kmeans(splited_tf_idf.class$train, 2)

cluster.class <- data.frame(names = rownames(splited_tf_idf.class$train), cluster = as.numeric(k_mean_res$cluster))
print(cluster.class)
```

On esssaye maintenant de deviner quel cluster correspond le mieux aux classes PHY et PSY:
- on recupère les indices des classes réelles
```{r}
index_PHY = grepl("PHY", cluster.class$names)
index_PSY = grepl("PSY", cluster.class$names)

cluster.class$is.PHY <- index_PHY
cluster.class$is.PSY <- index_PSY
```

- on fait la moyenne des numéro de cluster pour chacune des classes
```{r}
mean_cluster_PHY <- mean(cluster.class$cluster[index_PHY])
mean_cluster_PSY <- mean(cluster.class$cluster[index_PSY])
data.frame(classe_reelle = c("PHY", "PSY"), moyenne_des_clusters = c(mean_cluster_PHY, mean_cluster_PSY))
```

On attribut le numéro du cluster à sa classe la plus proche
```{r}
num_cluster_PHY <- if(mean_cluster_PHY < mean_cluster_PSY) 1 else 2
num_cluster_PSY <- if(mean_cluster_PSY < mean_cluster_PHY) 1 else 2
data.frame(classe_reelle = c("PHY", "PSY"), moyenne_des_clusters = c(num_cluster_PHY, num_cluster_PSY))
```

On peut maitenant attribuer un centroide aux classes
```{r}
centroide.PHY <- k_mean_res$centers[num_cluster_PHY,]
centroide.PSY <- k_mean_res$centers[num_cluster_PSY,]
data.frame(centroide.PHY, centroide.PSY)
```

On peut prévoir comme auparavant les classes par la similarité de chaque element de l'ensemble de test aux deux centroides
- on calcule la similarité de chaque elements à chaque centroide
```{r}
prediction <- data.frame(cours = rownames(splited_tf_idf.class$test),
                                     sim.PSY = as.double(cosinus.vm(centroide.PSY, t(splited_tf_idf.class$test))),
                                     sim.PHY = as.double(cosinus.vm(centroide.PHY, t(splited_tf_idf.class$test))))
prediction
```

- on normalise entre 0 et 1 pour obtenir une probabilité
```{r}
prediction$pred.PSY <- apply(prediction, 1, function (v) {as.numeric(v['sim.PSY']) / (as.numeric(v['sim.PHY']) + as.numeric(v['sim.PSY']))})
prediction$pred.PHY <- apply(prediction, 1, function (v) {as.numeric(v['sim.PHY']) / (as.numeric(v['sim.PHY']) + as.numeric(v['sim.PSY']))})
prediction
```

On ajoute une colonne de label des classes réelles pour facilité la construction de la courbe de ROC par la suite
```{r}
prediction$is.PSY <- 0
prediction$is.PHY <- 0
prediction$is.PSY[grepl("PSY", prediction$cours)] <- 1
prediction$is.PHY[grepl("PHY", prediction$cours)] <- 1
prediction
```

On peut maintenant construire une courbe ROC et une valeur d'AUC
```{r}
prediction.roc <- roc(prediction$is.PSY, prediction$pred.PSY, levels=c(0,1), direction="<", plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE, print.auc=TRUE, show.thres=TRUE)

```

On va maintenant mettre tout cela dans une fonction et faire des essais pour plusieures valeurs du nombre de dimentions
```{r}
apply_k_mean <- function(m, nfolds, fold) {
  splited_m <- split_data(nfolds, fold, m)
  
  k_mean_res <- kmeans(splited_m$train, 2)
  
  cluster.class <- data.frame(names = rownames(splited_m$train), cluster = as.numeric(k_mean_res$cluster))
  
  index_PHY = grepl("PHY", cluster.class$names)
  index_PSY = grepl("PSY", cluster.class$names)
  
  cluster.class$is.PHY <- index_PHY
  cluster.class$is.PSY <- index_PSY
  
  mean_cluster_PHY <- mean(cluster.class$cluster[index_PHY])
  mean_cluster_PSY <- mean(cluster.class$cluster[index_PSY])
  
  num_cluster_PHY <- if(mean_cluster_PHY < mean_cluster_PSY) 1 else 2
  num_cluster_PSY <- if(mean_cluster_PSY < mean_cluster_PHY) 1 else 2
  
  centroide.PHY <- k_mean_res$centers[num_cluster_PHY,]
  centroide.PSY <- k_mean_res$centers[num_cluster_PSY,]
  
  prediction <- data.frame(cours = rownames(splited_m$test),
                                     sim.PSY = as.double(cosinus.vm(centroide.PSY, t(splited_m$test))),
                                     sim.PHY = as.double(cosinus.vm(centroide.PHY, t(splited_m$test))))

  prediction$pred.PSY <- apply(prediction, 1, function (v) {as.numeric(v['sim.PSY']) / (as.numeric(v['sim.PHY']) + as.numeric(v['sim.PSY']))})
  prediction$pred.PHY <- apply(prediction, 1, function (v) {as.numeric(v['sim.PHY']) / (as.numeric(v['sim.PHY']) + as.numeric(v['sim.PSY']))})

  prediction$is.PSY <- 0
  prediction$is.PHY <- 0
  prediction$is.PSY[grepl("PSY", prediction$cours)] <- 1
  prediction$is.PHY[grepl("PHY", prediction$cours)] <- 1

  return(prediction)
}
```

On crée une fonction pour effecteur la k-fold cross validation
```{r}
cross_validation_k_mean <- function(m, nfolds) {
  result <- lapply(1:nfolds , function(fold) {
    prediction <- apply_k_mean(m, nfolds, fold)
    prediction.roc <- roc(prediction$is.PSY, prediction$pred.PSY, levels=c(0,1), direction="<")
    return(prediction.roc$auc)
  })
}

# prediction.class.kmean <- apply_k_mean(reduce_tf_idf.class)
results <- cross_validation_k_mean(reduce_tf_idf.class, 5)
data.frame(essais = 1:5, AUC = as.double(results))
```
On peut voir que l'algorithme K-mean n'arrive pas  toujours départager les deux clusters (quelques résultats à 0.70)

Il faudrait équilibrer les deux nombres de cours par matières pour obtenir des meilleures clusters
```{r}
nb_max_cours = min(sum(grepl("PHY", prediction.class.kmean$names)), sum(grepl("PSY", prediction.class.kmean$names)))
reduce_tf_idf.class.equi <- rbind(reduce_tf_idf.PSY[1:nb_max_cours,], reduce_tf_idf.PHY[1:nb_max_cours,])
```


On relance le même algorithme
```{r}
results.equi <- cross_validation_k_mean(reduce_tf_idf.class.equi, 5)
data.frame(essais = 1:5, AUC = as.double(results.equi))
```
On a singulièrement augmenté l'AUC du model

## Question 4

**À partir de la validation croisée de la tâche de classification ci-dessus, déterminez le nombre de dimensions latentes optimal de SVD selon une approche dite wrapper**

On réalise la même étude sur les dimentions que précedement
```{r}
get_auc_by_dimention_kmean <- function(dim_redu, tf_idf) {
  m.svd <- irlba(t(tf_idf), dim_redu)
  reduce_tf_idf <- m.svd$u[, 1:dim_redu] %*% diag(m.svd$d[1:dim_redu])
  rownames(reduce_tf_idf) <- colnames(tf_idf)

  reduce_tf_idf.class <- subset(reduce_tf_idf, grepl("PSY|PHY", rownames(reduce_tf_idf)))
  
  results <- cross_validation_k_mean(reduce_tf_idf.class, 10)
  return(mean(as.double(results)))
}
```


```{r}
dim_min = 2
dim_max = 50
auc_by_dimentions <- mclapply(dim_min:dim_max, get_auc_by_dimention_kmean, tf_idf, mc.cores = detectCores())
plot(dim_min:dim_max, auc_by_dimentions)
```
On peut maintenant se demander si on peut faire la réduction de dimention sur uniquement les cours PHY et PSY
¨
```{r}
tf_idf.class <- tf_idf[,grepl("PSY|PHY", rownames(t(tf_idf)))]

dim_min = 2
dim_max = 50
auc_by_dimentions <- mclapply(dim_min:dim_max, get_auc_by_dimention_kmean, tf_idf.class, mc.cores = detectCores())
plot(dim_min:dim_max, auc_by_dimentions)
```
On peut voir que cela a tendance à rendre notre modèle inconsistant, et le fait légèrement overfitté, pour ne pas dépasser les 0.9 en moyenne